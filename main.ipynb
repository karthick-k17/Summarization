{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "from nltk import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_file = PyPDF2.PdfReader('./2024-dbir-data-breach-investigations-report.pdf')\n",
    "pages = pdf_file.pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 2024 DBIR IntroductionIntroduction\n",
      "Greetings! Welcome to Verizon’s 2024 Data Breach Investigations Report (DBIR). \n",
      "This year marks the 17th edition of this publication, and we are thrilled to welcome \n",
      "back our old friends and say hello to new readers. As always, the aim of the DBIR is \n",
      "to shine a light on the various Actor types, the tactics they utilize and the targets they \n",
      "choose. Thanks to our talented, generous and civic-minded contributors from around \n",
      "the world who continue to stick with us and share their data and insight, and deep \n",
      "appreciation for our very own Verizon Threat Research Advisory Center (VTRAC) \n",
      "team (rock stars that they are). These two groups enable us to examine and analyze \n",
      "relevant trends in cybercrime that play out on a global stage across organizations of \n",
      "all sizes and types.\n",
      "From year to year, we see new and innovative attacks as well as variations on tried-\n",
      "and-true attacks that still remain successful. From the exploitation of well-known \n",
      "and far-reaching zero-day vulnerabilities, such as the one that affected MOVEit, to \n",
      "the much more mundane but still incredibly effective Ransomware and Denial of \n",
      "Service (DoS) attacks, criminals continue to do their utmost to prove the old adage \n",
      "“crime does not pay” wrong.\n",
      "The shifting landscape of cyber threats can be confusing and overwhelming. When, \n",
      "in addition to the attack types mentioned above, one throws in factors such as the \n",
      "human element and/or poorly protected passwords, things become even more \n",
      "confused. One might be forgiven for viewing the current state of cybersecurity \n",
      "as a colorful cyber Mardi Gras parade. Enterprise floats of all shapes and sizes \n",
      "cruising past a large crowd of threat actors who are shouting out gleefully “Throw \n",
      "me some creds!” Of course, human nature being what it is, all too often, the folks \n",
      "on the floats do just that. And, as with all such parades, what is left in the aftermath \n",
      "isn’t necessarily pretty. The past year has been a busy one for cybercrime. We \n",
      "analyzed 30,458 real-world security incidents, of which 10,626 were confirmed data \n",
      "breaches (a record high!), with victims spanning 94 countries.\n",
      "While the general structure of the report remains the same, long-time readers may \n",
      "notice a few changes. For example, the “first-time reader” section is now located in \n",
      "Appendix A rather than at the beginning of the report. But we do encourage those \n",
      "who are new to the DBIR to give it a read-through before diving into the report. It \n",
      "should help you get your bearings.\n",
      "Last, but certainly not least, we extend a most sincere thanks yet again to our \n",
      "contributors (without whom we could not do this) and to our readers (without whom \n",
      "there would be no point in doing it).\n",
      "Sincerely,\n",
      "The Verizon DBIR Team \n",
      "C. David Hylender, Philippe Langlois, Alex Pinto, Suzanne Widup\n",
      "Very special thanks to:\n",
      "– Christopher Novak for his continued support and insight\n",
      "– Dave Kennedy and Erika Gifford from VTRAC\n",
      "–  Kate Kutchko, Marziyeh Khanouki and Yoni Fridman from the Verizon Business \n",
      "Product Data Science Team\n"
     ]
    }
   ],
   "source": [
    "# for page in pages:\n",
    "#     page_text = page.extract_text()\n",
    "#     print(page_text)\n",
    "page_text = pages[4].extract_text()\n",
    "print(page_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Start to convert ./introduction_page.pdf\n",
      "[INFO] \u001b[1;36m[1/4] Opening document...\u001b[0m\n",
      "[INFO] \u001b[1;36m[2/4] Analyzing document...\u001b[0m\n",
      "[WARNING] Words count: 0. It might be a scanned pdf, which is not supported yet.\n",
      "[INFO] \u001b[1;36m[3/4] Parsing pages...\u001b[0m\n",
      "[INFO] (1/1) Page 1\n",
      "[INFO] \u001b[1;36m[4/4] Creating pages...\u001b[0m\n",
      "[INFO] (1/1) Page 1\n",
      "[INFO] Terminated in 1.89s.\n"
     ]
    }
   ],
   "source": [
    "from pdf2docx import Converter\n",
    "\n",
    "docx_file = ('./introduction_docx.docx')\n",
    "cv = Converter('./introduction_page.pdf')\n",
    "cv.convert(docx_file)\n",
    "cv.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<docx.text.paragraph.Paragraph object at 0x0000019C638DE330>\n",
      "['']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import docx\n",
    "\n",
    "doc = docx.Document('./introduction_docx.docx')\n",
    "full_text = []\n",
    "for para in doc.paragraphs:\n",
    "    print(para.t)\n",
    "    full_text.append(para.text)\n",
    "\n",
    "print(full_text)\n",
    "print(\"\\n\".join(full_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(page_text)\n",
    "total_documents = len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_frequency_matrix(sentences):\n",
    "    frequency_matrix = {}\n",
    "    stopWords = set(stopwords.words(\"english\"))\n",
    "    ps = PorterStemmer()\n",
    "    for sent in sentences:\n",
    "        freq_table = {}\n",
    "        words = word_tokenize(sent)\n",
    "        for word in words:\n",
    "            word = word.lower()\n",
    "            word = ps.stem(word)\n",
    "            if word in stopWords:\n",
    "                continue\n",
    "            if word in freq_table:\n",
    "                freq_table[word] += 1\n",
    "            else:\n",
    "                freq_table[word] = 1\n",
    "\n",
    "    return frequency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_matrix(freq_matrix):\n",
    "    tf_matrix = {}\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        tf_table = {}\n",
    "        count_words_in_sentence = len(f_table)\n",
    "        for word, count in f_table.items():\n",
    "            tf_table[word] = count / count_words_in_sentence\n",
    "        tf_matrix[sent] = tf_table\n",
    "\n",
    "    return tf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_documents_per_words(freq_matrix):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
